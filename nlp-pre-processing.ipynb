{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nnltk.download('punkt')\nimport re\nimport spacy\nimport string\n\npd.options.mode.chained_assignment = None\n\n","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('../input/customer-support-on-twitter/twcs/twcs.csv',nrows=6000)\ndata.head()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   tweet_id   author_id  inbound                      created_at  \\\n0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n\n                                                text response_tweet_id  \\\n0  @115712 I understand. I would like to assist y...                 2   \n1      @sprintcare and how do you propose we do that               NaN   \n2  @sprintcare I have sent several private messag...                 1   \n3  @115712 Please send us a Private Message so th...                 3   \n4                                 @sprintcare I did.                 4   \n\n   in_response_to_tweet_id  \n0                      3.0  \n1                      1.0  \n2                      4.0  \n3                      5.0  \n4                      6.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>inbound</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_tweet_id</th>\n      <th>in_response_to_tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n      <td>@115712 I understand. I would like to assist y...</td>\n      <td>2</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n      <td>@sprintcare I have sent several private messag...</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n      <td>@115712 Please send us a Private Message so th...</td>\n      <td>3</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n      <td>@sprintcare I did.</td>\n      <td>4</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = data[['text']] ## wit only double brackets createsa new dataframe\ndf['text'] = df['text'].astype(str)\ndf.head()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  @115712 I understand. I would like to assist y...\n1      @sprintcare and how do you propose we do that\n2  @sprintcare I have sent several private messag...\n3  @115712 Please send us a Private Message so th...\n4                                 @sprintcare I did.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 I understand. I would like to assist y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare I have sent several private messag...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 Please send us a Private Message so th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare I did.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Lower Casing**","metadata":{}},{"cell_type":"code","source":"df['text'] = df['text'].str.lower()\ndf.head()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  @115712 i understand. i would like to assist y...\n1      @sprintcare and how do you propose we do that\n2  @sprintcare i have sent several private messag...\n3  @115712 please send us a private message so th...\n4                                 @sprintcare i did.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# to remove punctuation use basic python string\nimport string\nPUNCT_TO_REMOVE = string.punctuation\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\ndf[\"text_wo_punct\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\ndf.head()               ","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \n0  115712 i understand i would like to assist you...  \n1       sprintcare and how do you propose we do that  \n2  sprintcare i have sent several private message...  \n3  115712 please send us a private message so tha...  \n4                                   sprintcare i did  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# remove stopwords\nfrom nltk.corpus import stopwords\nvocab = stopwords.words('english')\n","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def remove_stop_words(text):\n    return \" \".join([word for word in text.split(' ') if word not in vocab]) ","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df[\"stopword_removed\"] = df[\"text_wo_punct\"].apply(lambda text: remove_stop_words(text))\ndf.head()","metadata":{"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n\n                                    stopword_removed  \n0  115712 understand would like assist would need...  \n1                                 sprintcare propose  \n2  sprintcare sent several private messages one r...  \n3  115712 please send us private message assist c...  \n4                                         sprintcare  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n      <th>stopword_removed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 understand would like assist would need...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcare propose</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcare sent several private messages one r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 please send us private message assist c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n      <td>sprintcare</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# getting the most common words\nfrom collections import Counter\ncnt = Counter()\nfor text in df[\"stopword_removed\"].values:\n    for word in text.split():\n        cnt[word] += 1\n        \ncnt.most_common(10)","metadata":{"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"[('us', 934),\n ('please', 764),\n ('dm', 651),\n ('help', 597),\n ('thanks', 417),\n ('hi', 401),\n ('get', 368),\n ('sorry', 332),\n ('know', 300),\n ('im', 291)]"},"metadata":{}}]},{"cell_type":"code","source":"cnt.most_common(10)\nmost_common_words = set([items[0] for items in cnt.most_common(10)])","metadata":{"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def remove_frequent_words(text):\n    return \" \".join([word for word in text.split(\" \") if word not in most_common_words])","metadata":{"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"df[\"text_wo_frequent\"] = df[\"stopword_removed\"].apply(lambda text: remove_frequent_words(text))\ndf.head()","metadata":{"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n\n                                    stopword_removed  \\\n0  115712 understand would like assist would need...   \n1                                 sprintcare propose   \n2  sprintcare sent several private messages one r...   \n3  115712 please send us private message assist c...   \n4                                         sprintcare   \n\n                                    text_wo_frequent  \n0  115712 understand would like assist would need...  \n1                                 sprintcare propose  \n2  sprintcare sent several private messages one r...  \n3  115712 send private message assist click ‚Äòmess...  \n4                                         sprintcare  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n      <th>stopword_removed</th>\n      <th>text_wo_frequent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 understand would like assist would need...</td>\n      <td>115712 understand would like assist would need...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcare propose</td>\n      <td>sprintcare propose</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcare sent several private messages one r...</td>\n      <td>sprintcare sent several private messages one r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 please send us private message assist c...</td>\n      <td>115712 send private message assist click ‚Äòmess...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n      <td>sprintcare</td>\n      <td>sprintcare</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# removing rare words\n\nno_of_rare_words = 15\nrare_words = set([w for (w, c) in cnt.most_common()[:-no_of_rare_words-1:-1]])\n\ndef remove_rare_words(text):\n    return \" \".join([word for word in text.split(\" \") if word not in rare_words])\n\ndf[\"text_wo_rare\"] = df[\"text_wo_frequent\"].apply(lambda text: remove_rare_words(text))","metadata":{"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# We can combine all the list of words (stopwords, frequent words and rare words) \n# and create a single list to remove them at once.","metadata":{"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Stemming","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nstemer = PorterStemmer()","metadata":{"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def stemmer(text):\n    return \" \".join([stemer.stem(word) for word in text.split(\" \")])\n\ndf[\"stemmed\"] = df[\"text_wo_punct\"].apply(lambda text: stemmer(text))\ndf.head()","metadata":{"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n\n                                    stopword_removed  \\\n0  115712 understand would like assist would need...   \n1                                 sprintcare propose   \n2  sprintcare sent several private messages one r...   \n3  115712 please send us private message assist c...   \n4                                         sprintcare   \n\n                                    text_wo_frequent  \\\n0  115712 understand would like assist would need...   \n1                                 sprintcare propose   \n2  sprintcare sent several private messages one r...   \n3  115712 send private message assist click ‚Äòmess...   \n4                                         sprintcare   \n\n                                        text_wo_rare  \\\n0  115712 understand would like assist would need...   \n1                                 sprintcare propose   \n2  sprintcare sent several private messages one r...   \n3  115712 send private message assist click ‚Äòmess...   \n4                                         sprintcare   \n\n                                             stemmed  \n0  115712 i understand i would like to assist you...  \n1         sprintcar and how do you propos we do that  \n2  sprintcar i have sent sever privat messag and ...  \n3  115712 pleas send us a privat messag so that w...  \n4                                    sprintcar i did  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n      <th>stopword_removed</th>\n      <th>text_wo_frequent</th>\n      <th>text_wo_rare</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 understand would like assist would need...</td>\n      <td>115712 understand would like assist would need...</td>\n      <td>115712 understand would like assist would need...</td>\n      <td>115712 i understand i would like to assist you...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcare propose</td>\n      <td>sprintcare propose</td>\n      <td>sprintcare propose</td>\n      <td>sprintcar and how do you propos we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcare sent several private messages one r...</td>\n      <td>sprintcare sent several private messages one r...</td>\n      <td>sprintcare sent several private messages one r...</td>\n      <td>sprintcar i have sent sever privat messag and ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 please send us private message assist c...</td>\n      <td>115712 send private message assist click ‚Äòmess...</td>\n      <td>115712 send private message assist click ‚Äòmess...</td>\n      <td>115712 pleas send us a privat messag so that w...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n      <td>sprintcare</td>\n      <td>sprintcare</td>\n      <td>sprintcare</td>\n      <td>sprintcar i did</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see that words like private and propose have their e at the end chopped off due to stemming. This is not intented. What can we do fort hat? We can use Lemmatization in such cases.\n\nAlso this porter stemmer is for English language. If we are working with other languages, we can use snowball stemmer. The supported languages for snowball stemmer are","metadata":{}},{"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\nSnowballStemmer.languages","metadata":{"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"('danish',\n 'dutch',\n 'english',\n 'finnish',\n 'french',\n 'german',\n 'hungarian',\n 'italian',\n 'norwegian',\n 'porter',\n 'portuguese',\n 'romanian',\n 'russian',\n 'spanish',\n 'swedish')"},"metadata":{}}]},{"cell_type":"code","source":"#Lemmatization\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize(text):\n    return \" \".join([lemmatizer.lemmatize(word) for word in text.split(\" \")])\n\n\ndf[\"lematized\"] = df[\"text_wo_punct\"].apply(lambda text: lemmatize(text))\ndf.head()\n\n","metadata":{"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n\n                                             stemmed  \\\n0  115712 i understand i would like to assist you...   \n1         sprintcar and how do you propos we do that   \n2  sprintcar i have sent sever privat messag and ...   \n3  115712 pleas send us a privat messag so that w...   \n4                                    sprintcar i did   \n\n                                           lematized  \n0  115712 i understand i would like to assist you...  \n1       sprintcare and how do you propose we do that  \n2  sprintcare i have sent several private message...  \n3  115712 please send u a private message so that...  \n4                                   sprintcare i did  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n      <th>stemmed</th>\n      <th>lematized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 i understand i would like to assist you...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcar and how do you propos we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcar i have sent sever privat messag and ...</td>\n      <td>sprintcare i have sent several private message...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 pleas send us a privat messag so that w...</td>\n      <td>115712 please send u a private message so that...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n      <td>sprintcar i did</td>\n      <td>sprintcare i did</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### see the difference between stemming and lemmatizing above","metadata":{}},{"cell_type":"code","source":"df.drop([\"stopword_removed\",\"text_wo_frequent\",\"text_wo_rare\"],axis=1,inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n\n                                             stemmed  \n0  115712 i understand i would like to assist you...  \n1         sprintcar and how do you propos we do that  \n2  sprintcar i have sent sever privat messag and ...  \n3  115712 pleas send us a privat messag so that w...  \n4                                    sprintcar i did  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 i understand i would like to assist you...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcar and how do you propos we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcar i have sent sever privat messag and ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 pleas send us a privat messag so that w...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n      <td>sprintcar i did</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## some idea about lemmatizer\n\nlemmatizer.lemmatize(\"running\")","metadata":{"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"'running'"},"metadata":{}}]},{"cell_type":"markdown","source":"Wow. It returned running as such without converting it to the root form run. This is because the lemmatization process depends on the POS tag to come up with the correct lemma. Now let us lemmatize again by providing the POS tag for the word.","metadata":{}},{"cell_type":"code","source":"lemmatizer.lemmatize(\"running\",'v')","metadata":{"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"'run'"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we are getting the root form run. So we also need to provide the POS tag of the word along with the word for lemmatizer in nltk. Depending on the POS, the lemmatizer may return different results.\n\nLet us take the example, stripes and check the lemma when it is both verb and noun.","metadata":{}},{"cell_type":"code","source":"print(\"Word is : stripes\")\nprint(\"Lemma result for verb : \",lemmatizer.lemmatize(\"stripes\", 'v'))\nprint(\"Lemma result for noun : \",lemmatizer.lemmatize(\"stripes\", 'n'))","metadata":{"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Word is : stripes\nLemma result for verb :  strip\nLemma result for noun :  stripe\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\nwordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\ndef lemmatize_words(text):\n    pos_tagged_text = nltk.pos_tag(text.split())\n    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n\ndf[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\ndf.head()","metadata":{"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  @115712 i understand. i would like to assist y...   \n1      @sprintcare and how do you propose we do that   \n2  @sprintcare i have sent several private messag...   \n3  @115712 please send us a private message so th...   \n4                                 @sprintcare i did.   \n\n                                       text_wo_punct  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send us a private message so tha...   \n4                                   sprintcare i did   \n\n                                             stemmed  \\\n0  115712 i understand i would like to assist you...   \n1         sprintcar and how do you propos we do that   \n2  sprintcar i have sent sever privat messag and ...   \n3  115712 pleas send us a privat messag so that w...   \n4                                    sprintcar i did   \n\n                                           lematized  \\\n0  115712 i understand i would like to assist you...   \n1       sprintcare and how do you propose we do that   \n2  sprintcare i have sent several private message...   \n3  115712 please send u a private message so that...   \n4                                   sprintcare i did   \n\n                                     text_lemmatized  \n0  @115712 i understand. i would like to assist y...  \n1      @sprintcare and how do you propose we do that  \n2  @sprintcare i have send several private messag...  \n3  @115712 please send u a private message so tha...  \n4                                 @sprintcare i did.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_wo_punct</th>\n      <th>stemmed</th>\n      <th>lematized</th>\n      <th>text_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@115712 i understand. i would like to assist y...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>115712 i understand i would like to assist you...</td>\n      <td>@115712 i understand. i would like to assist y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>sprintcar and how do you propos we do that</td>\n      <td>sprintcare and how do you propose we do that</td>\n      <td>@sprintcare and how do you propose we do that</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@sprintcare i have sent several private messag...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>sprintcar i have sent sever privat messag and ...</td>\n      <td>sprintcare i have sent several private message...</td>\n      <td>@sprintcare i have send several private messag...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@115712 please send us a private message so th...</td>\n      <td>115712 please send us a private message so tha...</td>\n      <td>115712 pleas send us a privat messag so that w...</td>\n      <td>115712 please send u a private message so that...</td>\n      <td>@115712 please send u a private message so tha...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@sprintcare i did.</td>\n      <td>sprintcare i did</td>\n      <td>sprintcar i did</td>\n      <td>sprintcare i did</td>\n      <td>@sprintcare i did.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Removal of emojis","metadata":{}},{"cell_type":"code","source":"def remove_emoji(string):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\n\nremove_emoji(\"game is on üî•üî•\")","metadata":{"trusted":true},"execution_count":120,"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"'game is on '"},"metadata":{}}]},{"cell_type":"code","source":"remove_emoji(\"HilariousüòÇ\")\n","metadata":{"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"'Hilarious'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# got the list from open sourced git profile of NeelShah\nEMOTICONS = {\n    u\":‚Äë\\)\":\"Happy face or smiley\",\n    u\":\\)\":\"Happy face or smiley\",\n    u\":-\\]\":\"Happy face or smiley\",\n    u\":\\]\":\"Happy face or smiley\",\n    u\":-3\":\"Happy face smiley\",\n    u\":3\":\"Happy face smiley\",\n    u\":->\":\"Happy face smiley\",\n    u\":>\":\"Happy face smiley\",\n    u\"8-\\)\":\"Happy face smiley\",\n    u\":o\\)\":\"Happy face smiley\",\n    u\":-\\}\":\"Happy face smiley\",\n    u\":\\}\":\"Happy face smiley\",\n    u\":-\\)\":\"Happy face smiley\",\n    u\":c\\)\":\"Happy face smiley\",\n    u\":\\^\\)\":\"Happy face smiley\",\n    u\"=\\]\":\"Happy face smiley\",\n    u\"=\\)\":\"Happy face smiley\",\n    u\":‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n    u\":D\":\"Laughing, big grin or laugh with glasses\",\n    u\"8‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n    u\"X‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n    u\":-\\)\\)\":\"Very happy\",\n    u\":‚Äë\\(\":\"Frown, sad, andry or pouting\",\n    u\":-\\(\":\"Frown, sad, andry or pouting\",\n    u\":\\(\":\"Frown, sad, andry or pouting\",\n    u\":‚Äëc\":\"Frown, sad, andry or pouting\",\n    u\":c\":\"Frown, sad, andry or pouting\",\n    u\":‚Äë<\":\"Frown, sad, andry or pouting\",\n    u\":<\":\"Frown, sad, andry or pouting\",\n    u\":‚Äë\\[\":\"Frown, sad, andry or pouting\",\n    u\":\\[\":\"Frown, sad, andry or pouting\",\n    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n    u\">:\\[\":\"Frown, sad, andry or pouting\",\n    u\":\\{\":\"Frown, sad, andry or pouting\",\n    u\":@\":\"Frown, sad, andry or pouting\",\n    u\">:\\(\":\"Frown, sad, andry or pouting\",\n    u\":'‚Äë\\(\":\"Crying\",\n    u\":'\\(\":\"Crying\",\n    u\":'‚Äë\\)\":\"Tears of happiness\",\n    u\":'\\)\":\"Tears of happiness\",\n    u\"D‚Äë':\":\"Horror\",\n    u\"D:<\":\"Disgust\",\n    u\"D:\":\"Sadness\",\n    u\"D8\":\"Great dismay\",\n    u\"D;\":\"Great dismay\",\n    u\"D=\":\"Great dismay\",\n    u\"DX\":\"Great dismay\",\n    u\":‚ÄëO\":\"Surprise\",\n    u\":O\":\"Surprise\",\n    u\":‚Äëo\":\"Surprise\",\n    u\":o\":\"Surprise\",\n    u\":-0\":\"Shock\",\n    u\"8‚Äë0\":\"Yawn\",\n    u\">:O\":\"Yawn\",\n    u\":-\\*\":\"Kiss\",\n    u\":\\*\":\"Kiss\",\n    u\":X\":\"Kiss\",\n    u\";‚Äë\\)\":\"Wink or smirk\",\n    u\";\\)\":\"Wink or smirk\",\n    u\"\\*-\\)\":\"Wink or smirk\",\n    u\"\\*\\)\":\"Wink or smirk\",\n    u\";‚Äë\\]\":\"Wink or smirk\",\n    u\";\\]\":\"Wink or smirk\",\n    u\";\\^\\)\":\"Wink or smirk\",\n    u\":‚Äë,\":\"Wink or smirk\",\n    u\";D\":\"Wink or smirk\",\n    u\":‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"X‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":‚Äë√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":‚Äë/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":‚Äë\\|\":\"Straight face\",\n    u\":\\|\":\"Straight face\",\n    u\":$\":\"Embarrassed or blushing\",\n    u\":‚Äëx\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":‚Äë#\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":‚Äë&\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\"O:‚Äë\\)\":\"Angel, saint or innocent\",\n    u\"O:\\)\":\"Angel, saint or innocent\",\n    u\"0:‚Äë3\":\"Angel, saint or innocent\",\n    u\"0:3\":\"Angel, saint or innocent\",\n    u\"0:‚Äë\\)\":\"Angel, saint or innocent\",\n    u\"0:\\)\":\"Angel, saint or innocent\",\n    u\":‚Äëb\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n    u\">:‚Äë\\)\":\"Evil or devilish\",\n    u\">:\\)\":\"Evil or devilish\",\n    u\"\\}:‚Äë\\)\":\"Evil or devilish\",\n    u\"\\}:\\)\":\"Evil or devilish\",\n    u\"3:‚Äë\\)\":\"Evil or devilish\",\n    u\"3:\\)\":\"Evil or devilish\",\n    u\">;\\)\":\"Evil or devilish\",\n    u\"\\|;‚Äë\\)\":\"Cool\",\n    u\"\\|‚ÄëO\":\"Bored\",\n    u\":‚ÄëJ\":\"Tongue-in-cheek\",\n    u\"#‚Äë\\)\":\"Party all night\",\n    u\"%‚Äë\\)\":\"Drunk or confused\",\n    u\"%\\)\":\"Drunk or confused\",\n    u\":-###..\":\"Being sick\",\n    u\":###..\":\"Being sick\",\n    u\"<:‚Äë\\|\":\"Dump\",\n    u\"\\(>_<\\)\":\"Troubled\",\n    u\"\\(>_<\\)>\":\"Troubled\",\n    u\"\\(';'\\)\":\"Baby\",\n    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(~_~;\\) \\(„Éª\\.„Éª;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(-_-\\)zzz\":\"Sleeping\",\n    u\"\\(\\^_-\\)\":\"Wink\",\n    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n    u\"\\(\\+o\\+\\)\":\"Confused\",\n    u\"\\(o\\|o\\)\":\"Ultraman\",\n    u\"\\^_\\^\":\"Joyful\",\n    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n    u\"\\(\\^O\\^\\)Ôºè\":\"Joyful\",\n    u\"\\(\\^o\\^\\)Ôºè\":\"Joyful\",\n    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"\\('_'\\)\":\"Sad or Crying\",\n    u\"\\(/_;\\)\":\"Sad or Crying\",\n    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n    u\"\\(;_;\":\"Sad of Crying\",\n    u\"\\(;_:\\)\":\"Sad or Crying\",\n    u\"\\(;O;\\)\":\"Sad or Crying\",\n    u\"\\(:_;\\)\":\"Sad or Crying\",\n    u\"\\(ToT\\)\":\"Sad or Crying\",\n    u\";_;\":\"Sad or Crying\",\n    u\";-;\":\"Sad or Crying\",\n    u\";n;\":\"Sad or Crying\",\n    u\";;\":\"Sad or Crying\",\n    u\"Q\\.Q\":\"Sad or Crying\",\n    u\"T\\.T\":\"Sad or Crying\",\n    u\"QQ\":\"Sad or Crying\",\n    u\"Q_Q\":\"Sad or Crying\",\n    u\"\\(-\\.-\\)\":\"Shame\",\n    u\"\\(-_-\\)\":\"Shame\",\n    u\"\\(‰∏Ä‰∏Ä\\)\":\"Shame\",\n    u\"\\(Ôºõ‰∏Ä_‰∏Ä\\)\":\"Shame\",\n    u\"\\(=_=\\)\":\"Tired\",\n    u\"\\(=\\^\\¬∑\\^=\\)\":\"cat\",\n    u\"\\(=\\^\\¬∑\\¬∑\\^=\\)\":\"cat\",\n    u\"=_\\^=\t\":\"cat\",\n    u\"\\(\\.\\.\\)\":\"Looking down\",\n    u\"\\(\\._\\.\\)\":\"Looking down\",\n    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n    u\"\\(\\„Éª\\„Éª?\":\"Confusion\",\n    u\"\\(?_?\\)\":\"Confusion\",\n    u\">\\^_\\^<\":\"Normal Laugh\",\n    u\"<\\^!\\^>\":\"Normal Laugh\",\n    u\"\\^/\\^\":\"Normal Laugh\",\n    u\"\\Ôºà\\*\\^_\\^\\*Ôºâ\" :\"Normal Laugh\",\n    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n    u\"\\(^\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n    u\"\\(\\^‚Äî\\^\\Ôºâ\":\"Normal Laugh\",\n    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n    u\"\\Ôºà\\^‚Äî\\^\\Ôºâ\":\"Waving\",\n    u\"\\(;_;\\)/~~~\":\"Waving\",\n    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n    u\"\\(-_-\\)/~~~ \\($\\¬∑\\¬∑\\)/~~~\":\"Waving\",\n    u\"\\(T_T\\)/~~~\":\"Waving\",\n    u\"\\(ToT\\)/~~~\":\"Waving\",\n    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n    u\"\\(\\*_\\*\\)\":\"Amazed\",\n    u\"\\(\\*_\\*;\":\"Amazed\",\n    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n    u'\\(-\"-\\)':\"Worried\",\n    u\"\\(„Éº„Éº;\\)\":\"Worried\",\n    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n    u\"\\(\\ÔºæÔΩñ\\Ôºæ\\)\":\"Happy\",\n    u\"\\(\\ÔºæÔΩï\\Ôºæ\\)\":\"Happy\",\n    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n    u\"\\(\\^O\\^\\)\":\"Happy\",\n    u\"\\(\\^o\\^\\)\":\"Happy\",\n    u\"\\)\\^o\\^\\(\":\"Happy\",\n    u\":O o_O\":\"Surprised\",\n    u\"o_0\":\"Surprised\",\n    u\"o\\.O\":\"Surpised\",\n    u\"\\(o\\.o\\)\":\"Surprised\",\n    u\"oO\":\"Surprised\",\n    u\"\\(\\*Ôø£mÔø£\\)\":\"Dissatisfied\",\n    u\"\\(‚ÄòA`\\)\":\"Snubbed or Deflated\"\n}","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"def remove_emoticons(text):\n    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n    return emoticon_pattern.sub(r'', text)\n\nremove_emoticons(\"Hello :-)\")\n","metadata":{"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"'Hello '"},"metadata":{}}]},{"cell_type":"markdown","source":"#### sometimes not removing the emoticons and emojis can help understand the emotion in certain task like sentiment\n\n## Conversion of Emoticon to Words","metadata":{}},{"cell_type":"code","source":"def convert_emoticons(text):\n    for emot in EMOTICONS:\n        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n    return text\n\ntext = \"Hello :-) :-)\"\nconvert_emoticons(text)","metadata":{"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"'Hello Happy_face_smiley Happy_face_smiley'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Conversion of Emoji to Words\n\n## link to get the all emoji mapped\nhttps://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing?scriptVersionId=19201884&cellId=41","metadata":{}},{"cell_type":"code","source":"def convert_emojis(text):\n    for emot in UNICODE_EMO:\n        text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n    return text\n\ntext = \"game is on üî•\"\nconvert_emojis(text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Removal of urls","metadata":{}},{"cell_type":"code","source":"def remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)","metadata":{"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"text = \"Driverless AI NLP blog post on https://www.h2o.ai/blog/detecting-sarcasm-is-difficult-but-ai-may-have-an-answer/\"\nremove_urls(text)","metadata":{"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"'Driverless AI NLP blog post on '"},"metadata":{}}]},{"cell_type":"markdown","source":"## Removal of HTML Tags","metadata":{}},{"cell_type":"code","source":"def remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)\n\ntext = \"\"\"<div>\n<h1> H2O</h1>\n<p> AutoML</p>\n<a href=\"https://www.h2o.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n</div>\"\"\"\n\nprint(remove_html(text))","metadata":{"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"\n H2O\n AutoML\n Driverless AI\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Chat Words Conversion\nThis is an important text preprocessing step if we are dealing with chat data. People do use a lot of abbreviated words in chat and so it might be helpful to expand those words for our analysis purposes.\n\nGot a good list of chat slang words from this repo. We can use this for our conversion here. We can add more words to this list.","metadata":{}},{"cell_type":"code","source":"chat_words_str = \"\"\"\nAFAIK=As Far As I Know\nAFK=Away From Keyboard\nASAP=As Soon As Possible\nATK=At The Keyboard\nATM=At The Moment\nA3=Anytime, Anywhere, Anyplace\nBAK=Back At Keyboard\nBBL=Be Back Later\nBBS=Be Back Soon\nBFN=Bye For Now\nB4N=Bye For Now\nBRB=Be Right Back\nBRT=Be Right There\nBTW=By The Way\nB4=Before\nB4N=Bye For Now\nCU=See You\nCUL8R=See You Later\nCYA=See You\nFAQ=Frequently Asked Questions\nFC=Fingers Crossed\nFWIW=For What It's Worth\nFYI=For Your Information\nGAL=Get A Life\nGG=Good Game\nGN=Good Night\nGMTA=Great Minds Think Alike\nGR8=Great!\nG9=Genius\nIC=I See\nICQ=I Seek you (also a chat program)\nILU=ILU: I Love You\nIMHO=In My Honest/Humble Opinion\nIMO=In My Opinion\nIOW=In Other Words\nIRL=In Real Life\nKISS=Keep It Simple, Stupid\nLDR=Long Distance Relationship\nLMAO=Laugh My A.. Off\nLOL=Laughing Out Loud\nLTNS=Long Time No See\nL8R=Later\nMTE=My Thoughts Exactly\nM8=Mate\nNRN=No Reply Necessary\nOIC=Oh I See\nPITA=Pain In The A..\nPRT=Party\nPRW=Parents Are Watching\nROFL=Rolling On The Floor Laughing\nROFLOL=Rolling On The Floor Laughing Out Loud\nROTFLMAO=Rolling On The Floor Laughing My A.. Off\nSK8=Skate\nSTATS=Your sex and age\nASL=Age, Sex, Location\nTHX=Thank You\nTTFN=Ta-Ta For Now!\nTTYL=Talk To You Later\nU=You\nU2=You Too\nU4E=Yours For Ever\nWB=Welcome Back\nWTF=What The F...\nWTG=Way To Go!\nWUF=Where Are You From?\nW8=Wait...\n7K=Sick:-D Laugher\n\"\"\"","metadata":{"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"text = \"WUF=Where Are You From?\"\nx = text.split(\"=\")\nprint(x[0], x[1])","metadata":{"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"WUF Where Are You From?\n","output_type":"stream"}]},{"cell_type":"code","source":"# creating a dictionary from the above string variable\n# just for fun haha\nslangs = {}\nfor line in chat_words_str.split('\\n')[1:-1]:\n    splits = line.split(\"=\")\n    slang = splits[0]\n    abb = splits[1]\n    slangs[slang] = str(abb)\n    #print(splits[1])\n","metadata":{"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"def chat_words_conversion(text):\n    sen = \"\"\n    for word in text.split(\" \"):\n        if word not in slangs.keys():\n            sen = sen+\" \"+word\n        else:\n            abb = slangs[word]\n            sen = sen+\" \"+abb\n    return sen\n\ndef chat_words_conversion(text):\n    new_text = []\n    for w in text.split():\n        if w.upper() in chat_words_list:\n            new_text.append(chat_words_map_dict[w.upper()])\n        else:\n            new_text.append(w)\n    return \" \".join(new_text)\n\n\n    \nchat_words_conversion(\"one minute BRB\")","metadata":{"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"' one minute Be Right Back'"},"metadata":{}}]},{"cell_type":"markdown","source":"# If you want to use list but dont want to return a list then use \n\n## ................... \" \".join(list you wish to return)","metadata":{}},{"cell_type":"markdown","source":"# Spelling correcion","metadata":{}},{"cell_type":"code","source":"!pip install pyspellchecker\n","metadata":{"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"Collecting pyspellchecker\n  Downloading pyspellchecker-0.6.2-py3-none-any.whl (2.7 MB)\n\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.7 MB 2.2 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.6.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from spellchecker import SpellChecker\n\nspell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)\n        \ntext = \"speling correctin\"\ncorrect_spellings(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}